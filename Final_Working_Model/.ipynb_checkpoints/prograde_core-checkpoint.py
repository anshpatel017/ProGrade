#!/usr/bin/env python
#
# ProGrade - Rule-Based Repository Analyzer (robust clone + accurate commit counting + repo name)
#
import os
import git
import shutil
import re
import json
import stat
import tempfile
import time
import gc
import platform
import subprocess
from collections import defaultdict
from typing import Dict, List, Any, Tuple
from urllib.parse import urlparse

# --- (unchanged) TECH_DEFINITIONS, DOMAIN_KEYWORDS, COMMENT_MARKERS, MULTI_COMMENT_* ---
TECH_DEFINITIONS = {
    "languages": {
        "Python": [".py"], "JavaScript": [".js"], "HTML": [".html", ".htm"],
        "CSS": [".css"], "Java": [".java"], "TypeScript": [".ts"],
        "C++": [".cpp", ".h", ".hpp"], "C#": [".cs"], "Ruby": [".rb"],
        "Go": [".go"], "Swift": [".swift"], "Kotlin": [".kt"],
        "PHP": [".php"], "Dart": [".dart"],
    },
    "frameworks": {
        "React": ["react", ".jsx", ".tsx"], "Express.js": ["express"],
        "Next.js": ["next"], "Vue.js": ["vue", ".vue"], "Angular": ["@angular/core"],
        "Django": ["django"], "Flask": ["flask"], "FastAPI": ["fastapi"],
        "Spring Boot": ["spring-boot"], "Flutter": [".dart"], "Jupyter Notebook": [".ipynb"],
        "Pygame": ["pygame"], "Electron.js": ["electron"],
    },
    "databases": {
        "MongoDB": ["mongoose", "mongodb", "mongodb://"],
        "PostgreSQL": ["psycopg2", "pg", "postgres", "postgresql://"],
        "MySQL": ["mysql", "mysql2", "mysql-connector"],
        "SQLite": ["sqlite3", ".sqlite"], "Redis": ["redis"],
        "Firebase Realtime Database": ["firebase-admin", "firebase/database"],
    },
    "other_tools": {
        "Stripe": ["stripe", "api.stripe.com"], "Twilio": ["twilio", "api.twilio.com"],
        "AWS": ["boto3", "aws-sdk", ".amazonaws.com"],
        "Google Cloud Platform": ["google-cloud", "googleapis.com"],
        "Firebase": ["firebase"],
        "Docker": ["dockerfile"],
        "GitHub Actions": [".github/workflows"],
    },
    "ai_coding_assistants": {
        "Amazon CodeWhisperer": ["sourced from", "licensed under"],
        "GitHub Copilot (user-attributed)": ["generated by github copilot"],
        "Bolt.ai": ["bolt.ai", "made with bolt.ai", ".bolt"],
        "Lovable.ai": ["lovable.ai", "generated by lovable.ai"],
        "Cursor Editor": [".cursor-workspace"],
        "Replit AI": [".replit", "replit.nix"],
        "Sourcegraph Cody": ["cody.json"],
        "AI Code Generator (General)": ["generated by ai", "ai-generated code"],
    }
}

DOMAIN_KEYWORDS = {
    "AI / ML / Data Science": {'Jupyter Notebook', 'TensorFlow', 'PyTorch', 'Scikit-learn', 'Pandas'},
    "Mobile App Development": {'Kotlin', 'Swift', 'Flutter', 'React Native', 'Dart'},
    "Game Development": {'Unity', 'Unreal Engine', 'Pygame', 'Phaser'},
    "Cloud Computing / DevOps": {'Docker', 'GitHub Actions', 'AWS', 'Terraform', 'Kubernetes'},
    "Cybersecurity / Networking": {'Scapy', 'Wireshark', 'Nmap', 'Metasplot'},
    "Internet of Things (IoT)": {'Arduino', 'Raspberry Pi', 'ESP32', 'MQTT'},
    "frontend_web": {'React', 'Angular', 'Vue.js', 'Svelte', 'HTML', 'CSS', 'JavaScript', 'TypeScript', 'Sass'},
    "backend_web": {'Express.js', 'Django', 'Flask', 'FastAPI', 'Spring Boot', 'Laravel', 'Node.js', 'PHP'},
    "general_desktop": {'Python', 'Java', 'C#', 'C++', 'C', 'Tkinter', 'JavaFX', 'Electron.js'}
}

COMMENT_MARKERS = {
    '.py': '#',
    '.js': '//',
    '.ts': '//',
    '.java': '//',
    '.c': '//',
    '.cpp': '//',
    '.h': '//',
    '.cs': '//',
    '.go': '//',
    '.rs': '//',
    '.swift': '//',
    '.kt': '//',
    '.rb': '#',
    '.php': '//',
}
MULTI_COMMENT_START = {'/*', '"""', "'''"}
MULTI_COMMENT_END = {'*/', '"""', "'''"}


# --- Helper rmtree that retries & fixes permissions & forces GC ---
def handle_rmtree_error(func, path, exc_info):
    """Error handler for shutil.rmtree to fix Windows PermissionError by setting writable and retrying."""
    try:
        os.chmod(path, stat.S_IWRITE)
        func(path)
    except Exception:
        pass  # let outer logic handle retries


def robust_rmtree(path: str, max_retries: int = 3, wait_between: float = 0.25):
    """
    Try to remove 'path' robustly on Windows and Unix:
      - attempt shutil.rmtree with onerror handler
      - if it fails with PermissionError, try to chmod all files to writable,
        call gc.collect(), sleep briefly, and retry.
      - on Windows as last resort call 'rmdir /S /Q "path"' via cmd
    """
    if not path or not os.path.exists(path):
        return
    last_exc = None
    for attempt in range(max_retries):
        try:
            shutil.rmtree(path, onerror=handle_rmtree_error)
            return
        except Exception as e:
            last_exc = e
            # Try to make files writable
            try:
                for root, dirs, files in os.walk(path):
                    for name in files:
                        fp = os.path.join(root, name)
                        try:
                            os.chmod(fp, stat.S_IWRITE)
                        except Exception:
                            pass
                    for d in dirs:
                        dp = os.path.join(root, d)
                        try:
                            os.chmod(dp, stat.S_IWRITE)
                        except Exception:
                            pass
            except Exception:
                pass
            # Force garbage collection to release handles, sleep a little
            gc.collect()
            time.sleep(wait_between)
    # final fallback for Windows: use cmd rmdir
    if platform.system().lower().startswith("win"):
        try:
            cmd = ['cmd', '/c', 'rmdir', '/S', '/Q', path]
            subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            return
        except Exception:
            pass
    # if still here, raise last exception
    if last_exc:
        raise last_exc
    else:
        # last resort
        raise RuntimeError(f"Could not remove path: {path}")


# --- Utility to get displayable repo name from remote URL or input URL ---
def parse_repo_name_from_url(url: str) -> str:
    """
    Parse a repo display name from a remote URL:
      - supports SSH ('git@github.com:owner/repo.git')
      - supports HTTPS ('https://github.com/owner/repo.git')
      - returns 'owner/repo' (without .git) when possible, else basename
    """
    if not url:
        return ""
    url = url.strip()
    # SSH style: git@github.com:owner/repo.git
    if url.startswith("git@") and ":" in url:
        try:
            path = url.split(":", 1)[1]
            if path.endswith(".git"):
                path = path[:-4]
            return path
        except Exception:
            pass
    # HTTPS or other URL
    try:
        parsed = urlparse(url)
        path = parsed.path or url
        # remove leading slash
        if path.startswith("/"):
            path = path[1:]
        if path.endswith(".git"):
            path = path[:-4]
        return path
    except Exception:
        # fallback: just return last path segment without .git
        try:
            base = os.path.basename(url)
            if base.endswith(".git"):
                base = base[:-4]
            return base
        except Exception:
            return url


# --- 3. CORE ANALYSIS FUNCTIONS (with accurate unique-commit-per-author counting) ---

def analyze_repository(repo_path: str) -> Dict[str, Any]:
    """
    The main analysis engine. Walks the repo and performs all analysis.
    Counts unique commits per author (deduped by commit hexsha) across all refs.
    """
    tech_stack = defaultdict(set)
    scores = {
        "code_quality": 0.0,
        "comment_management": 0.0,
        "documentation": 0.0,
        "contribution": 0.0,
        "overall": 0.0
    }
    code_stats = {"code_lines": 0, "comment_lines": 0}
    # map author_id -> set of commit SHAs to avoid double-counting the same commit
    contributors_commits = defaultdict(set)

    repo_name = os.path.basename(os.path.normpath(repo_path))
    has_linter = False
    readme_word_count = 0

    # Git-based Analysis (Contributors)
    try:
        repo = git.Repo(repo_path)
        # iterate across all refs to capture entire history, but dedupe using commit.hexsha
        try:
            for commit in repo.iter_commits('--all'):
                # normalize author identity: prefer name, fall back to email
                author_name = None
                try:
                    author_name = (commit.author.name or "").strip()
                except Exception:
                    author_name = None
                if not author_name:
                    try:
                        author_name = (commit.author.email or "").strip()
                    except Exception:
                        author_name = "unknown"
                if not author_name:
                    author_name = "unknown"

                # add commit SHA to that author's set
                try:
                    contributors_commits[author_name].add(commit.hexsha)
                except Exception:
                    # fallback: if hexsha missing, add by object id
                    contributors_commits[author_name].add(getattr(commit, 'hexsha', repr(commit)))
        except Exception:
            # Could be empty repo, no HEAD, or other issue - ignore gracefuly
            pass
        # release repo reference
        try:
            if hasattr(repo, 'close'):
                repo.close()
        except Exception:
            pass
        del repo
        gc.collect()
    except Exception as e:
        # non-fatal - continue analysis without git history
        print(f"  [Warn] Could not analyze git history: {e}")

    # File System Walk (Tech Stack, Code/Comment Ratio)
    dependency_files = {}

    for root, dirs, files in os.walk(repo_path):
        # skip .git directory completely
        if '.git' in root.split(os.sep):
            continue

        for d in dirs:
            d_lower = d.lower()
            if d_lower == '.bolt':
                tech_stack["ai_coding_assistants"].add("Bolt.ai")
            if d_lower == '.cursor-workspace':
                tech_stack["ai_coding_assistants"].add("Cursor Editor")
            if d_lower in ['tests', 'test', '__tests__']:
                # presence of test folder contributes to heuristics later
                pass

        for file in files:
            file_path = os.path.join(root, file)
            file_lower = file.lower()
            _, ext = os.path.splitext(file_lower)

            if '.github/workflows' in root.replace('\\', '/'):
                tech_stack["other_tools"].add("GitHub Actions")
            if file_lower == 'dockerfile':
                tech_stack["other_tools"].add("Docker")
            if file_lower in ['.replit', 'replit.nix']:
                tech_stack["ai_coding_assistants"].add("Replit AI")
            if file_lower.startswith('.eslintrc'):
                has_linter = True
            if file_lower == '.prettierrc':
                has_linter = True
            if file_lower == 'pyproject.toml':
                has_linter = True

            if file_lower.startswith('readme'):
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        readme_word_count = max(readme_word_count, len(re.findall(r'\b\w+\b', f.read())))
                except Exception:
                    pass

            if file_lower in ['package.json', 'requirements.txt', 'pom.xml']:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        dependency_files[file_lower] = f.read().lower()
                except Exception:
                    pass

            for tech, patterns in TECH_DEFINITIONS["languages"].items():
                if ext in patterns:
                    tech_stack["languages"].add(tech)
            for tech, patterns in TECH_DEFINITIONS["frameworks"].items():
                if ext in patterns:
                    tech_stack["frameworks"].add(tech)

            if ext in COMMENT_MARKERS:
                in_multi_comment = False
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        for line in f:
                            line = line.strip()
                            if not line:
                                continue
                            if any(line.startswith(m) for m in MULTI_COMMENT_START):
                                in_multi_comment = True
                            if in_multi_comment:
                                code_stats["comment_lines"] += 1
                                if any(line.endswith(m) for m in MULTI_COMMENT_END):
                                    in_multi_comment = False
                            elif line.startswith(COMMENT_MARKERS[ext]):
                                code_stats["comment_lines"] += 1
                            else:
                                code_stats["code_lines"] += 1
                except Exception:
                    pass

    # Content Analysis
    all_content = " ".join(dependency_files.values())
    for category_key, category in TECH_DEFINITIONS.items():
        if category_key == "languages":
            continue
        for tech, patterns in category.items():
            for pattern in patterns:
                if pattern.startswith("."):
                    continue
                if pattern in all_content:
                    tech_stack[category_key].add(tech)

    # Domain Assignment
    all_detected_tech = set()
    for tech_set in tech_stack.values():
        all_detected_tech.update(tech_set)

    domains = set()
    if all_detected_tech.intersection(DOMAIN_KEYWORDS["AI / ML / Data Science"]):
        domains.add("AI / ML / Data Science")
    if all_detected_tech.intersection(DOMAIN_KEYWORDS["Mobile App Development"]):
        domains.add("Mobile App Development")
    if all_detected_tech.intersection(DOMAIN_KEYWORDS["Game Development"]):
        domains.add("Game Development")
    if all_detected_tech.intersection(DOMAIN_KEYWORDS["Cloud Computing / DevOps"]):
        domains.add("Cloud Computing / DevOps")
    if all_detected_tech.intersection(DOMAIN_KEYWORDS["Internet of Things (IoT)"]):
        domains.add("Internet of Things (IoT)")
    if all_detected_tech.intersection(DOMAIN_KEYWORDS["Cybersecurity / Networking"]):
        domains.add("Cybersecurity / Networking")

    is_frontend = bool(all_detected_tech.intersection(DOMAIN_KEYWORDS["frontend_web"]))
    is_backend = bool(all_detected_tech.intersection(DOMAIN_KEYWORDS["backend_web"]))

    if is_frontend and is_backend:
        domains.add("Full Stack Web Development")
    elif is_frontend:
        domains.add("Frontend Web Development")
    elif is_backend:
        domains.add("Backend Development / API Creation")

    if not domains and all_detected_tech.intersection(DOMAIN_KEYWORDS["general_desktop"]):
        domains.add("General Purpose / Desktop Applications")
    if not domains:
        domains.add("Miscellaneous / Other")

    # Scoring
    scores["code_quality"] = 10.0 if has_linter else 2.0

    total_lines = code_stats["code_lines"] + code_stats["comment_lines"]
    if total_lines == 0:
        scores["comment_management"] = 0.0
    else:
        ratio = code_stats["comment_lines"] / total_lines
        if ratio > 0.25:
            scores["comment_management"] = 10.0
        elif ratio > 0.15:
            scores["comment_management"] = 7.5
        elif ratio > 0.05:
            scores["comment_management"] = 4.0
        else:
            scores["comment_management"] = 1.0

    if readme_word_count > 300:
        scores["documentation"] = 10.0
    elif readme_word_count > 100:
        scores["documentation"] = 7.0
    elif readme_word_count > 0:
        scores["documentation"] = 3.0
    else:
        scores["documentation"] = 0.0

    # Now convert contributors_commits (author -> set of SHAs) to sorted list with counts
    contributors_counts = {author: len(shas) for author, shas in contributors_commits.items()}
    num_contributors = len(contributors_counts)
    if num_contributors > 5:
        scores["contribution"] = 10.0
    elif num_contributors > 2:
        scores["contribution"] = 7.0
    else:
        scores["contribution"] = 4.0

    total_score = scores["code_quality"] + scores["comment_management"] + scores["documentation"] + scores["contribution"]
    scores["overall"] = (total_score / 40.0) * 10.0

    # Build structured contributors list (name + commit count), sorted by count desc
    sorted_contributors = sorted(contributors_counts.items(), key=lambda item: item[1], reverse=True)
    top_contributors = [{"name": name, "commits": commits} for name, commits in sorted_contributors]

    # Convert sets to lists for nicer output
    tech_stack_out = {k: sorted(list(v)) for k, v in tech_stack.items()}

    return {
        "repo_name": repo_name,
        "tech_stack": tech_stack_out,
        "domains": sorted(list(domains)),
        "scores": scores,
        "contributors": top_contributors  # list of dicts with accurate counts
    }


# --- 4. MAIN EXECUTION (keeps robust clone + unshallow logic) ---
def main():
    print("--- ProGrade Rule-Based Repository Analyzer ---")

    repo_url = input("\nEnter the GitHub repository URL to analyze: \n> ").strip()
    if not repo_url:
        print("No URL provided. Exiting.")
        return

    TEMP_CLONE_DIR = tempfile.mkdtemp(prefix="prograde_clone_")
    repo_obj = None
    cloned = False
    repo_display_name = None
    try:
        # Attempt a shallow clone first (fast). We'll unshallow or reclone if necessary.
        try:
            print(f"\nCloning '{repo_url}' (shallow clone for speed)...")
            repo_obj = git.Repo.clone_from(repo_url, TEMP_CLONE_DIR, depth=1)
            cloned = True
            print("Shallow clone successful.")
        except Exception as e:
            print(f"Shallow clone failed: {e}")
            # try full clone directly
            try:
                print("Attempting full clone instead...")
                repo_obj = git.Repo.clone_from(repo_url, TEMP_CLONE_DIR)
                cloned = True
                print("Full clone successful.")
            except Exception as e2:
                raise RuntimeError(f"Could not clone repository (shallow and full clone attempts failed): {e2}")

        # Try to determine a nice displayable repo name from the remote if possible
        try:
            remote_url = None
            try:
                # prefer remote origin url
                if repo_obj.remotes and 'origin' in [r.name for r in repo_obj.remotes]:
                    remote_url = repo_obj.remotes.origin.url
                elif repo_obj.remotes:
                    # take first remote
                    remote_url = next(iter(repo_obj.remotes)).url
            except Exception:
                remote_url = None

            # fallback to the user input URL if remote not available
            if not remote_url:
                remote_url = repo_url

            parsed_name = parse_repo_name_from_url(remote_url)
            # if parse returns empty, fallback to temp dir basename
            if parsed_name:
                repo_display_name = parsed_name
            else:
                repo_display_name = os.path.basename(os.path.normpath(TEMP_CLONE_DIR))
        except Exception:
            repo_display_name = os.path.basename(os.path.normpath(TEMP_CLONE_DIR))

        # If shallow, try to unshallow. If unshallow fails, clean up and do a full clone.
        shallow_file = os.path.join(TEMP_CLONE_DIR, '.git', 'shallow')
        if os.path.exists(shallow_file):
            try:
                print("Detected shallow clone â€” fetching full history (this may take time)...")
                repo_obj.git.fetch('--unshallow')
                print("Successfully fetched full history (unshallowed).")
            except Exception:
                print("Could not unshallow via fetch --unshallow. Will retry with a full reclone.")
                # cleanup and reclone full
                try:
                    if repo_obj is not None:
                        try:
                            if hasattr(repo_obj, 'close'):
                                repo_obj.close()
                        except Exception:
                            pass
                        del repo_obj
                    gc.collect()
                except Exception:
                    pass
                try:
                    robust_rmtree(TEMP_CLONE_DIR)
                except Exception:
                    pass
                # recreate temp dir and full clone
                TEMP_CLONE_DIR = tempfile.mkdtemp(prefix="prograde_clone_")
                try:
                    print("Performing full clone (may take longer)...")
                    repo_obj = git.Repo.clone_from(repo_url, TEMP_CLONE_DIR)
                    print("Full clone successful.")
                except Exception as e3:
                    raise RuntimeError(f"Reclone (full) failed: {e3}")

        print("\nStarting analysis...")
        report_data = analyze_repository(TEMP_CLONE_DIR)
        print("Analysis complete.")

        # Print report (use repo_display_name in header)
        print("\n" + "="*50)
        print(f"ðŸš€ Analysis Report for: {repo_display_name}")
        print("="*50)

        report_order = ["languages", "frameworks", "databases", "other_tools", "ai_coding_assistants"]
        found_any_tech = False
        print("\nRepo Tech Stack (Detected):")
        for category in report_order:
            technologies = report_data['tech_stack'].get(category)
            if technologies:
                found_any_tech = True
                print(f"  --- {category.replace('_', ' ').title()} ---")
                for tech in sorted(list(technologies)):
                    print(f"    - {tech}")
        if not found_any_tech:
            print("  - (No specific technologies detected)")

        print(f"\nRepo Domain (Detected):")
        print(f"  - {', '.join(report_data['domains'])}")

        print(f"\nRepo Score (Heuristic):")
        scores = report_data['scores']
        print(f"  - Code Quality:       {scores['code_quality']:.1f} / 10.0")
        print(f"  - Comment Management: {scores['comment_management']:.1f} / 10.0")
        print(f"  - Documentation (README):  {scores['documentation']:.1f} / 10.0")
        print(f"  - Contribution:       {scores['contribution']:.1f} / 10.0")
        print("  ---------------------------------")
        print(f"  - Overall Score:      {scores['overall']:.1f} / 10.0")

        print(f"\nTop Contributors:")
        contributors = report_data['contributors']  # list of dicts: {"name":..., "commits":...}
        if not contributors:
            print("  - No contributor data found (empty repo or could not read history).")
        else:
            to_show = contributors if len(contributors) <= 3 else contributors[:3]
            for c in to_show:
                name = c.get("name", "unknown")
                commits = c.get("commits", 0)
                print(f"  - {name}: {commits} commit{'s' if commits != 1 else ''}")

        print("\n" + "="*50)

    except git.exc.GitCommandError as e:
        print(f"\nError: Could not clone repository.")
        print(f"Details: {e}")
        print("Please check if the URL is correct and the repository is public.")
    except Exception as e:
        print(f"\nAn unexpected error occurred: {e}")
    finally:
        # Attempt to explicitly remove repo object reference and collect garbage
        try:
            if 'repo_obj' in locals() and repo_obj is not None:
                try:
                    if hasattr(repo_obj, 'close'):
                        try:
                            repo_obj.close()
                        except Exception:
                            pass
                    del repo_obj
                except Exception:
                    pass
            gc.collect()
        except Exception:
            pass

        # Robust removal of temp clone dir
        if os.path.exists(TEMP_CLONE_DIR):
            print(f"\nCleaning up temporary files...")
            try:
                robust_rmtree(TEMP_CLONE_DIR)
                print("Cleanup complete.")
            except Exception as e:
                print("Cleanup failed (last resort):", e)


if __name__ == "__main__":
    main()
